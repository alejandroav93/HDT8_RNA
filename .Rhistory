modeloSVM_L<-svm(PriceRange~., data=train2, cost=0.7, kernel="linear")#95%
modeloSVM_R<-svm(PriceRange~., data=train2, gamma=2^-7, kernel="radial")
modeloSVM_R<-svm(PriceRange~., data=train2, gamma=2^3, kernel="radial")
prediccionL<-predict(modeloSVM_L,newdata=test[,1:4])
modeloSVM_L<-svm(PriceRange~., data=train2, cost=2^7, kernel="linear") #98%
modeloSVM_L<-svm(PriceRange~., data=train2, cost=2^-7, kernel="linear") #88%
modeloSVM_L<-svm(PriceRange~., data=train2, cost=0.7, kernel="linear")#95%
modeloSVM_R<-svm(PriceRange~., data=train2, gamma=2^-7, kernel="radial")
modeloSVM_R<-svm(PriceRange~., data=train2, gamma=2^3, kernel="radial")
modeloSVM_L1<-svm(PriceRange~., data=train2, cost=2^7, kernel="linear") #98%
modeloSVM_L2<-svm(PriceRange~., data=train2, cost=2^-7, kernel="linear") #88%
modeloSVM_L3<-svm(PriceRange~., data=train2, cost=0.7, kernel="linear")#95%
modeloSVM_R1<-svm(PriceRange~., data=train2, gamma=2^-7, kernel="radial")
modeloSVM_R2<-svm(PriceRange~., data=train2, gamma=2^3, kernel="radial")
plot(modeloSVM_L1,train2,OverallQual~YearBuilt)
plot(modeloSVM_L1,train2,OverallQual~YearBuilt)
plot(modeloSVM_L1,train2,OverallQual~YearBuilt)
modeloSVM_L1$index
plot(modeloSVM_L1,train2,OverallQual~YearBuilt)
modeloSVM_L1<-svm(PriceRange~., data=train2, cost=2^7, kernel="linear") #98%
modeloSVM_L2<-svm(PriceRange~., data=train2, cost=2^-7, kernel="linear") #88%
modeloSVM_L3<-svm(PriceRange~., data=train2, cost=0.7, kernel="linear")#95%
modeloSVM_R1<-svm(PriceRange~., data=train2, gamma=2^-7, kernel="radial")
modeloSVM_R2<-svm(PriceRange~., data=train2, gamma=2^3, kernel="radial")
plot(modeloSVM_L1,train2,OverallQual~YearBuilt)
modeloSVM_L1<-svm(PriceRange~., data=train2, cost=2^7, kernel="linear") #98%
plot(modeloSVM_L1,train2,OverallQual~YearBuilt)
modeloSVM_L1<-svm(PriceRange~., data=train2, cost=2^7, kernel="linear") #98%
summary(modeloSVM_L1)
plot(modeloSVM_L1,train2,OverallQual~YearBuilt)
prediccionL<-predict(modeloSVM_L1,newdata=test2[,])
prediccionR<-predict(modeloSVM_R1,newdata=test2[,])
modeloTuneado<-tune.svm(Species~., data=train2, cost=c(0.01,0.1,0.5,1,5,10,16,20,32), kernel="linear")
prediccionL<-predict(modeloSVM_L1,newdata=test2[,])
prediccionR<-predict(modeloSVM_R1,newdata=test2[,])
modeloTuneado<-tune.svm(PriceRange~., data=train2, cost=c(0.01,0.1,0.5,1,5,10,16,20,32), kernel="linear")
predMejorModelo<-predict(modeloTuneado$best.model,newdata = test2[,])
confusionMatrix(test2$PriceRange,prediccionL)
prediccionL<-predict(modeloSVM_L1,newdata=test2[,])
prediccionR<-predict(modeloSVM_R1,newdata=test2[,])
modeloTuneado<-tune.svm(PriceRange~., data=train2, cost=c(0.01,0.1,0.5,1,5,10,16,20,32), kernel="linear")
predMejorModelo<-predict(modeloTuneado$best.model,newdata = test2[,])
#confusionMatrix(test2$PriceRange,prediccionL)
#confusionMatrix(test2$PriceRange,prediccionR)
confusionMatrix(test2$PriceRange,predMejorModelo)
prediccionL<-predict(modeloSVM_L1,newdata=test2)
prediccionR<-predict(modeloSVM_R1,newdata=test2)
modeloTuneado<-tune.svm(PriceRange~., data=train2, cost=c(0.01,0.1,0.5,1,5,10,16,20,32), kernel="linear")
predMejorModelo<-predict(modeloTuneado$best.model,newdata = test2)
#confusionMatrix(test2$PriceRange,prediccionL)
#confusionMatrix(test2$PriceRange,prediccionR)
confusionMatrix(test2$PriceRange,predMejorModelo)
table(predMejorModelo)
table(test2)
set.seed(123)
#se toman las variables que se cree predicen propiamente el precio de la casa y el precio real de la casa.
#luego se reemplaza la columna del precio de la casa por una que lo clasifica como economica, intermedio o cara dependiendo de los percentiles.
data <- fread("./train.csv", select = c("OverallQual","GrLivArea", "GarageCars", "SalePrice", "YearBuilt"))
#data <- data %>% mutate(Economica = if_else(quant["0%"] <= SalePrice & SalePrice < quant["25%"], 1,0))
#data <- data %>% mutate(Intermedia = if_else(quant["25%"] <= SalePrice & SalePrice < quant["50%"], 1,0))
#data <- data %>% mutate(Cara = if_else(quant["50%"] <= SalePrice, 1,0))
data$OverallQual[data$OverallQual == 'NaN'] <- 0
data2 <- data %>% mutate(PriceRange = if_else(quant["0%"] <= SalePrice & SalePrice < quant["25%"], 0,
if_else(quant["25%"] <= SalePrice & SalePrice < quant["50%"], 1, 2) ))
data2$SalePrice <- NULL
data
data2
#-----CORRELACIONES------#
# Correlación de 80.98%
cor(data$OverallQual,data$Cara, method = "spearman")
corte <- sample(nrow(data),nrow(data)*0.7)
train<-data[corte,]
test<-data[-corte,]
corte2 <- sample(nrow(data2),nrow(data2)*0.7)
train2<-data2[corte2,]
test2<-data2[-corte2,]
modelosvm2<-svm(PriceRange~., data = train2, type = 'C-classification', scale = F)
summary(modelosvm2)
modelosvm2$index
plot(modelosvm2,train2,OverallQual~YearBuilt)
modeloSVM_L1<-svm(PriceRange~., data=train2, cost=2^7, kernel="linear") #98%
modeloSVM_L2<-svm(PriceRange~., data=train2, cost=2^-7, kernel="linear") #88%
modeloSVM_L3<-svm(PriceRange~., data=train2, cost=0.7, kernel="linear")#95%
modeloSVM_R1<-svm(PriceRange~., data=train2, gamma=2^-7, kernel="radial")
modeloSVM_R2<-svm(PriceRange~., data=train2, gamma=2^3, kernel="radial")
prediccionL<-predict(modeloSVM_L1,newdata=test2)
prediccionR<-predict(modeloSVM_R1,newdata=test2)
modeloTuneado<-tune.svm(PriceRange~., data=train2, cost=c(0.01,0.1,0.5,1,5,10,16,20,32), kernel="linear")
predMejorModelo<-predict(modeloTuneado$best.model,newdata = test2)
#confusionMatrix(test2$PriceRange,prediccionL)
#confusionMatrix(test2$PriceRange,prediccionR)
table(predMejorModelo)
table(test2)
#confusionMatrix(test2$PriceRange,predMejorModelo)
#table(predMejorModelo)
#table(test2)
confusionMatrix(test2$PriceRange,prediccionL)
View(modeloSVM_L1)
#table(predMejorModelo)
#table(test2)
confusionMatrix(test2$PriceRange,predMejorModelo)
str(test2)
#table(predMejorModelo)
#table(test2)
#confusionMatrix(test2$PriceRange,predMejorModelo)
str(train2)
#table(predMejorModelo)
#table(test2)
#confusionMatrix(test2$PriceRange,predMejorModelo)
set.seed(123)
#se toman las variables que se cree predicen propiamente el precio de la casa y el precio real de la casa.
#luego se reemplaza la columna del precio de la casa por una que lo clasifica como economica, intermedio o cara dependiendo de los percentiles.
data <- fread("./train.csv", select = c("OverallQual","GrLivArea", "GarageCars", "SalePrice", "YearBuilt"))
#data <- data %>% mutate(Economica = if_else(quant["0%"] <= SalePrice & SalePrice < quant["25%"], 1,0))
#data <- data %>% mutate(Intermedia = if_else(quant["25%"] <= SalePrice & SalePrice < quant["50%"], 1,0))
#data <- data %>% mutate(Cara = if_else(quant["50%"] <= SalePrice, 1,0))
data$OverallQual[data$OverallQual == 'NaN'] <- 0
data2 <- data %>% mutate(PriceRange = if_else(quant["0%"] <= SalePrice & SalePrice < quant["25%"], "Economica",
if_else(quant["25%"] <= SalePrice & SalePrice < quant["50%"], "Intermedia", "Cara") ))
data2$SalePrice <- NULL
data
data2
set.seed(123)
#se toman las variables que se cree predicen propiamente el precio de la casa y el precio real de la casa.
#luego se reemplaza la columna del precio de la casa por una que lo clasifica como economica, intermedio o cara dependiendo de los percentiles.
data <- fread("./train.csv", select = c("OverallQual","GrLivArea", "GarageCars", "SalePrice", "YearBuilt"))
#data <- data %>% mutate(Economica = if_else(quant["0%"] <= SalePrice & SalePrice < quant["25%"], 1,0))
#data <- data %>% mutate(Intermedia = if_else(quant["25%"] <= SalePrice & SalePrice < quant["50%"], 1,0))
#data <- data %>% mutate(Cara = if_else(quant["50%"] <= SalePrice, 1,0))
data$OverallQual[data$OverallQual == 'NaN'] <- 0
data2 <- data %>% mutate(PriceRange = if_else(quant["0%"] <= SalePrice & SalePrice < quant["25%"], "Economica",
if_else(quant["25%"] <= SalePrice & SalePrice < quant["50%"], "Intermedia", "Cara") ))
data2$SalePrice <- NULL
data2$PriceRange <- as.factor(data2$PriceRange)
data
data2
corte <- sample(nrow(data),nrow(data)*0.7)
train<-data[corte,]
test<-data[-corte,]
corte2 <- sample(nrow(data2),nrow(data2)*0.7)
train2<-data2[corte2,]
test2<-data2[-corte2,]
modeloSVM_L1<-svm(PriceRange~., data=train2, cost=2^7, kernel="linear")
modeloSVM_L2<-svm(PriceRange~., data=train2, cost=2^-7, kernel="linear")
modeloSVM_L3<-svm(PriceRange~., data=train2, cost=0.7, kernel="linear")
modeloSVM_R1<-svm(PriceRange~., data=train2, gamma=2^-7, kernel="radial")
modeloSVM_R2<-svm(PriceRange~., data=train2, gamma=2^3, kernel="radial")
prediccionL<-predict(modeloSVM_L1,newdata=test2)
prediccionR<-predict(modeloSVM_R1,newdata=test2)
modeloTuneado<-tune.svm(PriceRange~., data=train2, cost=c(0.01,0.1,0.5,1,5,10,16,20,32), kernel="linear")
predMejorModelo<-predict(modeloTuneado$best.model,newdata = test2)
confusionMatrix(test2$PriceRange,prediccionL)
confusionMatrix(test2$PriceRange,prediccionR)
#str(train2)
#table(predMejorModelo)
#table(test2)
confusionMatrix(test2$PriceRange,predMejorModelo)
modeloLineal<-tune.svm(PriceRange~., data=train2, cost=c(0.01,0.1,0.5,1,5,10,16,20,32), kernel="linear")
predMejorModelo<-predict(modeloLineal$best.model,newdata = test2)
modeloRadial<-tune.svm(PriceRange~., data=train2, cost=c(0.01,0.1,0.5,1,5,10,16,20,32), kernel="radial")
modeloLineal<-tune.svm(PriceRange~., data=train2, cost=c(0.01,0.1,0.5,1,5,10,16,20,32), kernel="linear")
predMejorModelo<-predict(modeloLineal$best.model,newdata = test2)
modeloRadial<-tune.svm(PriceRange~., data=train2, gamma=c(0.01,0.1,0.5,1,5,10,16,20,32), kernel="radial")
predMejorModelo2<-predict(modeloRadial$best.model,newdata = test2)
confusionMatrix(test2$PriceRange,predMejorModelo)
confusionMatrix(test2$PriceRange,predMejorModelo2)
confusionMatrix(train2$PriceRange,predMejorModelo)
predMejorModelo3<-predict(modeloLineal$best.model,newdata = train2)
predMejorModelo4<-predict(modeloRadial$best.model,newdata = train2)
confusionMatrix(train2$PriceRange,predMejorModelo3)
confusionMatrix(train2$PriceRange,predMejorModelo4)
knitr::opts_chunk$set(echo = TRUE)
library("tidyverse")
library("dplyr")
library("ggplot2")
library("httr")
library("readr")
library(rpart)
library(caret)
library(randomForest)
library(tree)
library(rpart.plot)
library(car)
library(cluster) #Para calcular la silueta
library(e1071)#para cmeans
library(mclust) #mixtures of gaussians
library(fpc) #para hacer el plotcluster
library(NbClust) #Para determinar el número de clusters óptimo
library(factoextra) #Para hacer gráficos bonitos de clustering
library(hopkins) #Para revisar si vale la pena hacer agrupamiento
library(GGally) #Para hacer el conjunto de graficos
library(FeatureImpCluster) #Para revisar la importancia de las variables en los grupos.
library(pheatmap) #Para hacer mapa de calor
house <- read.csv("./train.csv", stringsAsFactors = F)
quant <- quantile(house$SalePric)
set.seed(123)
#se toman las variables que se cree predicen propiamente el precio de la casa y el precio real de la casa.
#luego se reemplaza la columna del precio de la casa por una que lo clasifica como economica, intermedio o cara dependiendo de los percentiles.
data <- fread("./train.csv", select = c("OverallQual","OverallCond" ,"GrLivArea", "BedroomAbvGr", "TotRmsAbvGrd", "GarageCars", "SalePrice", "YearBuilt", "LotArea", "LotFrontage"))
data <- data %>% mutate(Economica = if_else(quant["0%"] <= SalePrice & SalePrice < quant["25%"], 1,0))
data <- data %>% mutate(Intermedia = if_else(quant["25%"] <= SalePrice & SalePrice < quant["50%"], 1,0))
data <- data %>% mutate(Cara = if_else(quant["50%"] <= SalePrice, 1,0))
data$OverallQual[data$OverallQual == 'NAN'] <- 0
data
#-----CORRELACIONES------#
# Correlación de 80.98%
cor(data$OverallQual,data$Cara, method = "spearman")
# Correlación de 69.07%
cor(data$GarageCars,data$Cara, method = "spearman")
# Correlación de 73.13%
cor(data$GrLivArea,data$Cara, method = "spearman")
# Correlación de 65.26%
cor(data$YearBuilt,data$Cara, method = "spearman")
corte <- sample(nrow(data),nrow(data)*0.7)
train<-data[corte,]
test<-data[-corte,]
modelo<-glm(train$Cara~., data = train[,c(1,3,6,8)], family = binomial(), maxit=100)
pred<-predict(modelo,newdata = test[,c(1,3,6,8)], type = "response")
prediccion<-ifelse(pred>=0.5,1,0)
confusionMatrix(as.factor(test$Cara),as.factor(prediccion))
pred<-predict(modelo,newdata = train[,c(1,3,6,8)], type = "response")
prediccion<-ifelse(pred>=0.5,1,0)
confusionMatrix(as.factor(train$Cara),as.factor(prediccion))
#se concluye que no hay overfitting dado que no existe una discrepancia significativa entre la precisión del modelo con el set de test y el de train
modelo2<-glm(train$Intermedia~., data = train[,c(1,3,6,8)], family = binomial(), maxit=100)
pred<-predict(modelo2,newdata = test[,c(1,3,6,8)], type = "response")
prediccion<-ifelse(pred>=0.5,1,0)
confusionMatrix(as.factor(test$Intermedia),as.factor(prediccion))
pred<-predict(modelo2,newdata = train[,c(1,3,6,8)], type = "response")
prediccion<-ifelse(pred>=0.5,1,0)
confusionMatrix(as.factor(train$Intermedia),as.factor(prediccion))
modelo3<-glm(train$Economica~., data = train[,c(1,3,6,8)], family = binomial(), maxit=100)
pred<-predict(modelo3,newdata = test[,c(1,3,6,8)], type = "response")
prediccion<-ifelse(pred>=0.5,1,0)
confusionMatrix(as.factor(test$Economica),as.factor(prediccion))
pred<-predict(modelo3,newdata = train[,c(1,3,6,8)], type = "response")
prediccion<-ifelse(pred>=0.5,1,0)
confusionMatrix(as.factor(train$Economica),as.factor(prediccion))
knitr::opts_chunk$set(echo = TRUE)
install.packages("nnet")
install.packages("RWeka")
install.packages("neuralnet")
library("tidyverse")
library("dplyr")
library("ggplot2")
library("httr")
library("readr")
library(rpart)
library(caret)
library(randomForest)
library(tree)
library(rpart.plot)
library(car)
library(cluster) #Para calcular la silueta
library(e1071)#para cmeans
library(mclust) #mixtures of gaussians
library(fpc) #para hacer el plotcluster
library(NbClust) #Para determinar el número de clusters óptimo
library(factoextra) #Para hacer gráficos bonitos de clustering
library(hopkins) #Para revisar si vale la pena hacer agrupamiento
library(GGally) #Para hacer el conjunto de graficos
library(FeatureImpCluster) #Para revisar la importancia de las variables en los grupos.
library(pheatmap) #Para hacer mapa de calor
library(caret)
library(nnet)
library(RWeka)
#install.packages("nnet")
#install.packages("RWeka")
#install.packages("neuralnet")
library("tidyverse")
library("dplyr")
library("ggplot2")
library("httr")
library("readr")
library(rpart)
library(caret)
library(randomForest)
library(tree)
library(rpart.plot)
library(car)
library(cluster) #Para calcular la silueta
library(e1071)#para cmeans
library(mclust) #mixtures of gaussians
library(fpc) #para hacer el plotcluster
library(NbClust) #Para determinar el número de clusters óptimo
library(factoextra) #Para hacer gráficos bonitos de clustering
library(hopkins) #Para revisar si vale la pena hacer agrupamiento
library(GGally) #Para hacer el conjunto de graficos
library(FeatureImpCluster) #Para revisar la importancia de las variables en los grupos.
library(pheatmap) #Para hacer mapa de calor
library(caret)
library(nnet)
library(RWeka)
#install.packages("nnet")
install.packages("RWeka")
#install.packages("neuralnet")
library("tidyverse")
library("dplyr")
library("ggplot2")
library("httr")
library("readr")
library(rpart)
library(caret)
library(randomForest)
library(tree)
library(rpart.plot)
library(car)
library(cluster) #Para calcular la silueta
library(e1071)#para cmeans
library(mclust) #mixtures of gaussians
library(fpc) #para hacer el plotcluster
library(NbClust) #Para determinar el número de clusters óptimo
library(factoextra) #Para hacer gráficos bonitos de clustering
library(hopkins) #Para revisar si vale la pena hacer agrupamiento
library(GGally) #Para hacer el conjunto de graficos
library(FeatureImpCluster) #Para revisar la importancia de las variables en los grupos.
library(pheatmap) #Para hacer mapa de calor
library(caret)
library(nnet)
library(RWeka)
knitr::opts_chunk$set(echo = TRUE)
#install.packages("nnet")
install.packages("RWeka")
#install.packages("neuralnet")
library("tidyverse")
library("dplyr")
library("ggplot2")
library("httr")
library("readr")
library(rpart)
library(caret)
library(randomForest)
library(tree)
library(rpart.plot)
library(car)
library(cluster) #Para calcular la silueta
library(e1071)#para cmeans
library(mclust) #mixtures of gaussians
library(fpc) #para hacer el plotcluster
library(NbClust) #Para determinar el número de clusters óptimo
library(factoextra) #Para hacer gráficos bonitos de clustering
library(hopkins) #Para revisar si vale la pena hacer agrupamiento
library(GGally) #Para hacer el conjunto de graficos
library(FeatureImpCluster) #Para revisar la importancia de las variables en los grupos.
library(pheatmap) #Para hacer mapa de calor
library(caret)
library(nnet)
library(RWeka)
library(neural)
#install.packages("nnet")
install.packages("RWeka")
#install.packages("neuralnet")
library("tidyverse")
library("dplyr")
library("ggplot2")
library("httr")
library("readr")
library(rpart)
library(caret)
library(randomForest)
library(tree)
library(rpart.plot)
library(car)
library(cluster) #Para calcular la silueta
library(e1071)#para cmeans
library(mclust) #mixtures of gaussians
library(fpc) #para hacer el plotcluster
library(NbClust) #Para determinar el número de clusters óptimo
library(factoextra) #Para hacer gráficos bonitos de clustering
library(hopkins) #Para revisar si vale la pena hacer agrupamiento
library(GGally) #Para hacer el conjunto de graficos
library(FeatureImpCluster) #Para revisar la importancia de las variables en los grupos.
library(pheatmap) #Para hacer mapa de calor
library(caret)
library(nnet)
library(RWeka)
library(neural)
library(dummy)
library(neuralnet)
install.packages("RWeka")
knitr::opts_chunk$set(echo = TRUE)
#install.packages("nnet")
#install.packages("RWeka")
#install.packages("neuralnet")
library("tidyverse")
library("dplyr")
library("ggplot2")
library("httr")
library("readr")
library(rpart)
library(caret)
library(randomForest)
library(tree)
library(rpart.plot)
library(car)
library(cluster) #Para calcular la silueta
library(e1071)#para cmeans
library(mclust) #mixtures of gaussians
library(fpc) #para hacer el plotcluster
library(NbClust) #Para determinar el número de clusters óptimo
library(factoextra) #Para hacer gráficos bonitos de clustering
library(hopkins) #Para revisar si vale la pena hacer agrupamiento
library(GGally) #Para hacer el conjunto de graficos
library(FeatureImpCluster) #Para revisar la importancia de las variables en los grupos.
library(pheatmap) #Para hacer mapa de calor
library(caret)
library(nnet)
library(RWeka)
library(neural)
library(dummy)
library(neuralnet)
house <- read.csv("./train.csv", stringsAsFactors = F)
quant <- quantile(house$SalePric)
set.seed(123)
#se toman las variables que se cree predicen propiamente el precio de la casa y el precio real de la casa.
#luego se reemplaza la columna del precio de la casa por una que lo clasifica como economica, intermedio o cara dependiendo de los percentiles.
data <- fread("./train.csv", select = c("OverallQual","GrLivArea", "GarageCars", "SalePrice", "YearBuilt"))
#data <- data %>% mutate(Economica = if_else(quant["0%"] <= SalePrice & SalePrice < quant["25%"], 1,0))
#data <- data %>% mutate(Intermedia = if_else(quant["25%"] <= SalePrice & SalePrice < quant["50%"], 1,0))
#data <- data %>% mutate(Cara = if_else(quant["50%"] <= SalePrice, 1,0))
data$OverallQual[data$OverallQual == 'NaN'] <- 0
data2 <- data %>% mutate(PriceRange = if_else(quant["0%"] <= SalePrice & SalePrice < quant["25%"], "Economica",
if_else(quant["25%"] <= SalePrice & SalePrice < quant["50%"], "Intermedia", "Cara") ))
data2$SalePrice <- NULL
data2$PriceRange <- as.factor(data2$PriceRange)
data
data2
set.seed(123)
#se toman las variables que se cree predicen propiamente el precio de la casa y el precio real de la casa.
#luego se reemplaza la columna del precio de la casa por una que lo clasifica como economica, intermedio o cara dependiendo de los percentiles.
data <- fread("./train.csv", select = c("OverallQual","GrLivArea", "GarageCars", "SalePrice", "YearBuilt"))
#data <- data %>% mutate(Economica = if_else(quant["0%"] <= SalePrice & SalePrice < quant["25%"], 1,0))
#data <- data %>% mutate(Intermedia = if_else(quant["25%"] <= SalePrice & SalePrice < quant["50%"], 1,0))
#data <- data %>% mutate(Cara = if_else(quant["50%"] <= SalePrice, 1,0))
data$OverallQual[data$OverallQual == 'NaN'] <- 0
data2 <- data %>% mutate(PriceRange = if_else(quant["0%"] <= SalePrice & SalePrice < quant["25%"], "Economica",
if_else(quant["25%"] <= SalePrice & SalePrice < quant["50%"], "Intermedia", "Cara") ))
data2$SalePrice <- NULL
data2$PriceRange <- as.factor(data2$PriceRange)
data
data2
corte <- sample(nrow(data),nrow(data)*0.7)
train<-data[corte,]
test<-data[-corte,]
corte2 <- sample(nrow(data2),nrow(data2)*0.7)
train2<-data2[corte2,]
test2<-data2[-corte2,]
redCaret <- train(PriceRange~., data=train, method="nnet", trace=F)
redCaret <- train(SalePrice~., data=train, method="nnet", trace=F)
test$prediccionCaret<-predict(redCaret, newdata = test[,1:4])
redCaret <- train(SalePrice~., data=train, method="nnet", trace=F)
test$prediccionCaret<-predict(redCaret, newdata = test)
cfmCaret<-confusionMatrix(test$prediccionCaret,test$SalePrice)
redCaret <- train(SalePrice~., data=train, method="nnet", trace=F)
test$prediccionCaret<-predict(redCaret, newdata = test)
test
cfmCaret<-confusionMatrix(test$prediccionCaret,test$SalePrice)
redCaret <- train2(PriceRange~., data=train2, method="nnet", trace=F)
corte <- sample(nrow(data),nrow(data)*0.7)
train<-data[corte,]
test<-data[-corte,]
corte2 <- sample(nrow(data2),nrow(data2)*0.7)
train2<-data2[corte2,]
test2<-data2[-corte2,]
redCaret <- train2(PriceRange~., data=train2, method="nnet", trace=F)
redCaret <- train(PriceRange~., data=train2, method="nnet", trace=F)
test2$prediccionCaret<-predict(redCaret, newdata = test2)
cfmCaret<-confusionMatrix(test2$prediccionCaret,test2$PriceRange)
cfmCaret
redCaret <- train(PriceRange~., data=train2, method="pcaNNet", trace=F)
test2$prediccionCaret<-predict(redCaret, newdata = test2)
cfmCaret<-confusionMatrix(test2$prediccionCaret,test2$PriceRange)
cfmCaret
redCaret <- train(PriceRange~., data=train2, method="nnet", trace=F)
test2$prediccionCaret<-predict(redCaret, newdata = test2)
cfmCaret<-confusionMatrix(test2$prediccionCaret,test2$PriceRange)
cfmCaret
redCaret2 <- train(PriceRange~., data=train2, method="pcaNNet", trace=F)
test2$prediccionCaret<-predict(redCaret2, newdata = test2)
cfmCaret2<-confusionMatrix(test2$prediccionCaret,test2$PriceRange)
cfmCaret2
redCaret3 <- train(SalePrice~., data=train, method="pcaNNet", trace=F)
test3$prediccionCaret<-predict(redCaret3, newdata = test)
redCaret3 <- train(SalePrice~., data=train, method="pcaNNet", trace=F)
test$prediccionCaret<-predict(redCaret3, newdata = test)
cfmCaret3<-confusionMatrix(test$prediccionCaret,test$SalePrice)
redCaret3 <- train(SalePrice~., data=train, type = c("Regression"), method="pcaNNet", trace=F)
test$prediccionCaret<-predict(redCaret3, newdata = test)
cfmCaret3<-confusionMatrix(test$prediccionCaret,test$SalePrice)
set.seed(123)
#se toman las variables que se cree predicen propiamente el precio de la casa y el precio real de la casa.
#luego se reemplaza la columna del precio de la casa por una que lo clasifica como economica, intermedio o cara dependiendo de los percentiles.
data <- fread("./train.csv", select = c("OverallQual","GrLivArea", "GarageCars", "SalePrice", "YearBuilt"))
#data <- data %>% mutate(Economica = if_else(quant["0%"] <= SalePrice & SalePrice < quant["25%"], 1,0))
#data <- data %>% mutate(Intermedia = if_else(quant["25%"] <= SalePrice & SalePrice < quant["50%"], 1,0))
#data <- data %>% mutate(Cara = if_else(quant["50%"] <= SalePrice, 1,0))
data$OverallQual[data$OverallQual == 'NaN'] <- 0
data2 <- data %>% mutate(PriceRange = if_else(quant["0%"] <= SalePrice & SalePrice < quant["25%"], "Economica",
if_else(quant["25%"] <= SalePrice & SalePrice < quant["50%"], "Intermedia", "Cara") ))
data2$SalePrice <- NULL
data2$PriceRange <- as.factor(data2$PriceRange)
data$SalePrice <- as.factor(data$SalePrice)
data
data2
redCaret3 <- train(SalePrice~., data=train, type = c("Regression"), method="pcaNNet", trace=F)
test$prediccionCaret<-predict(redCaret3, newdata = test)
cfmCaret3<-confusionMatrix(test$prediccionCaret,test$SalePrice)
redCaret3 <- train(SalePrice~., data=train, type = c("Regression"), method="pcaNNet", trace=F)
test$prediccionCaret<-predict(redCaret3, newdata = test)
test
cfmCaret3<-confusionMatrix(test$prediccionCaret,test$SalePrice)
redCaret3 <- train(SalePrice~., data=train, method="brnn", trace=F)
